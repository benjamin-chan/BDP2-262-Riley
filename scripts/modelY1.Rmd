# Model 1

Prediction model for `Y1`.


## Data preprocessing

Split data set into 60:40 training:validation samples.

```{r}
inTrain <- createDataPartition(df$id, p = 0.7)
dfTrain <- df[inTrain$Resample1, ]
dfValid <- df[-inTrain$Resample1, ]
```

Preprocess the training sample.

1. Exclude near-zero variance predictors
2. Center variables
3. Scale variables
4. Impute missing values using k-nearest neighbor

```{r}
preProc <-
  dfTrain %>% 
  select(-c(id, Y1, Y2, Y3)) %>% 
  preProcess(method = c("nzv", "corr", "medianImpute"))
preProc
dfTrainPreProc <- predict(preProc, dfTrain)
dfTrainPreProc %>% write.csv("data/processed/dfTrainPreProc.csv", row.names = FALSE)
```

## Training

Set the control parameters.

```{r}
ctrl <- trainControl(method = "repeatedcv",
                     number = 5,
                     repeats = 5,
                     savePredictions = TRUE,
                     allowParallel = TRUE,
                     search = "random")
```

Set the model.

```{r}
library(randomForest)
method <- "rf"
```

Set the tuning grid for model xgbTree.

```{r, eval = FALSE}
grid <- expand.grid(mtry = seq(5, 25, 5))
```

Fit model over the tuning parameters.

```{r}
trainingModel <- 
  train(Y1 ~ .,
        data = dfTrainPreProc %>% select(-c(id, Y2, Y3)),
        method = method,
        trControl = ctrl,
        # tuneGrid = grid,
        tuneLength = 10,
        nthreads = 3,
        na.action = "na.omit")
```
